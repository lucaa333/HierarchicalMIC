{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Baseline Flat Classification\n",
                "\n",
                "This notebook trains a **flat (non-hierarchical) classifier** on the merged 3D MedMNIST datasets for comparison with the hierarchical approach.\n",
                "\n",
                "The flat classifier predicts the fine-grained label directly without the intermediate region classification step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm\n",
                "\n",
                "from config import (\n",
                "    DEVICE, DATA_CONFIG, MODEL_CONFIG, TRAINING_CONFIG,\n",
                "    PATHS, set_seed, DEFAULT_MERGED_DATASETS\n",
                ")\n",
                "from utils.data_loader import create_hierarchical_dataset\n",
                "from utils.cnn_3d_models import get_3d_model\n",
                "from utils.trainer import Trainer\n",
                "\n",
                "set_seed(42)\n",
                "print(f\"Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Merged Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load all 5 merged datasets\n",
                "print(f\"Loading datasets: {DEFAULT_MERGED_DATASETS}\")\n",
                "\n",
                "train_loader, val_loader, test_loader, dataset_info = create_hierarchical_dataset(\n",
                "    datasets_to_include=DEFAULT_MERGED_DATASETS,\n",
                "    batch_size=DATA_CONFIG['batch_size'],\n",
                "    num_workers=DATA_CONFIG['num_workers']\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"MERGED DATASET INFO\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Datasets: {dataset_info['datasets_included']}\")\n",
                "print(f\"Train samples: {dataset_info['train_samples']:,}\")\n",
                "print(f\"Val samples: {dataset_info['val_samples']:,}\")\n",
                "print(f\"Test samples: {dataset_info['test_samples']:,}\")\n",
                "print(f\"Fine classes: {dataset_info['num_fine_classes']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Create Wrapper DataLoaders for Flat Training\n",
                "\n",
                "The hierarchical dataset returns `(img, coarse_label, fine_label)`. For flat training, we only need `(img, fine_label)`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FlatDataLoaderWrapper:\n",
                "    \"\"\"Wrapper that extracts only (img, fine_label) from hierarchical dataloader.\"\"\"\n",
                "    def __init__(self, hierarchical_loader):\n",
                "        self.loader = hierarchical_loader\n",
                "    \n",
                "    def __iter__(self):\n",
                "        for imgs, coarse_labels, fine_labels in self.loader:\n",
                "            yield imgs, fine_labels\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.loader)\n",
                "\n",
                "# Create flat loaders\n",
                "flat_train_loader = FlatDataLoaderWrapper(train_loader)\n",
                "flat_val_loader = FlatDataLoaderWrapper(val_loader)\n",
                "flat_test_loader = FlatDataLoaderWrapper(test_loader)\n",
                "\n",
                "print(\"\\n✓ Flat data loaders created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build Flat Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create flat classifier\n",
                "num_classes = dataset_info['num_fine_classes']\n",
                "architecture = MODEL_CONFIG['architecture']\n",
                "\n",
                "model = get_3d_model(\n",
                "    model_name=architecture,\n",
                "    num_classes=num_classes\n",
                ").to(DEVICE)\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "\n",
                "print(f\"\\nFlat classifier created:\")\n",
                "print(f\"  Architecture: {architecture}\")\n",
                "print(f\"  Number of classes: {num_classes}\")\n",
                "print(f\"  Total parameters: {total_params:,}\")\n",
                "print(f\"  Trainable parameters: {trainable_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Flat Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create trainer\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(\n",
                "    model.parameters(),\n",
                "    lr=TRAINING_CONFIG['learning_rate'],\n",
                "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
                ")\n",
                "scheduler = torch.optim.lr_scheduler.StepLR(\n",
                "    optimizer,\n",
                "    step_size=TRAINING_CONFIG['scheduler_step_size'],\n",
                "    gamma=TRAINING_CONFIG['scheduler_gamma']\n",
                ")\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    train_loader=flat_train_loader,\n",
                "    val_loader=flat_val_loader,\n",
                "    criterion=criterion,\n",
                "    optimizer=optimizer,\n",
                "    device=DEVICE,\n",
                "    scheduler=scheduler\n",
                ")\n",
                "\n",
                "# Total epochs = coarse + fine epochs for fair comparison\n",
                "total_epochs = TRAINING_CONFIG['coarse_epochs'] + TRAINING_CONFIG['fine_epochs']\n",
                "print(f\"Training for {total_epochs} epochs...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train\n",
                "history = trainer.train(num_epochs=total_epochs)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TRAINING COMPLETE!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
                "axes[0].plot(history['val_loss'], label='Val Loss', color='orange')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].set_title('Flat Classifier Loss')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Accuracy\n",
                "axes[1].plot(history['train_acc'], label='Train Acc', color='blue')\n",
                "axes[1].plot(history['val_acc'], label='Val Acc', color='orange')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Accuracy')\n",
                "axes[1].set_title('Flat Classifier Accuracy')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{PATHS['figures']}/baseline_training_{architecture}.png\", dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_flat_model(model, test_loader, device):\n",
                "    \"\"\"Evaluate flat model on test set.\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    correct = 0\n",
                "    total = 0\n",
                "    all_preds = []\n",
                "    all_labels = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for imgs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
                "            imgs = imgs.to(device, dtype=torch.float32)\n",
                "            if imgs.max() > 1:\n",
                "                imgs = imgs / 255.0\n",
                "            \n",
                "            labels = labels.squeeze(-1).long().to(device)\n",
                "            \n",
                "            outputs = model(imgs)\n",
                "            preds = outputs.argmax(1)\n",
                "            \n",
                "            correct += (preds == labels).sum().item()\n",
                "            total += imgs.size(0)\n",
                "            \n",
                "            all_preds.extend(preds.cpu().numpy())\n",
                "            all_labels.extend(labels.cpu().numpy())\n",
                "    \n",
                "    accuracy = correct / total if total > 0 else 0\n",
                "    \n",
                "    return {\n",
                "        'accuracy': accuracy,\n",
                "        'predictions': np.array(all_preds),\n",
                "        'labels': np.array(all_labels),\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate\n",
                "results = evaluate_flat_model(model, flat_test_loader, DEVICE)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TEST SET RESULTS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nTest Accuracy: {results['accuracy']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.makedirs(PATHS['models'], exist_ok=True)\n",
                "\n",
                "model_path = f\"{PATHS['models']}/baseline_{architecture}.pth\"\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "fffffffffflogsdjmjfjdfjdf,,kkkkddd\n",
                "torch.save({\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'dataset_info': dataset_info,\n",
                "    'history': history,\n",
                "    'test_results': results,\n",
                "    'config': {\n",
                "        'architecture': architecture,\n",
                "        'num_classes': num_classes,\n",
                "    }\n",
                "}, model_path)\n",
                "\n",
                "print(f\"\\n✓ Model saved to: {model_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TRAINING SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nDatasets used: {', '.join(dataset_info['datasets_included'])}\")\n",
                "print(f\"Total training samples: {dataset_info['train_samples']:,}\")\n",
                "print(f\"\\nModel architecture: {architecture}\")\n",
                "print(f\"Number of classes: {num_classes}\")\n",
                "print(f\"Total parameters: {total_params:,}\")\n",
                "print(f\"\\nFinal Test Accuracy: {results['accuracy']:.4f}\")\n",
                "print(f\"\\nModel saved to: {model_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
