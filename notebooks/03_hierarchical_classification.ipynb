{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fce9994",
   "metadata": {},
   "source": [
    "This notebook implements the hierarchical classification pipeline:\n",
    "\n",
    "Stage 1 (Coarse): Anatomical region localization (brain, abdomen, chest)\n",
    "Stage 2 (Fine): Region-specific pathology classification\n",
    "Stage 3 (Subtype): Disease subtype identification (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.hierarchical_model import HierarchicalClassificationModel\n",
    "from utils.coarse_classifier import CoarseAnatomicalClassifier\n",
    "from utils.fine_classifier import RegionSpecificPathologyNetwork\n",
    "from utils.data_loader import get_medmnist_dataloaders, create_hierarchical_dataset\n",
    "from utils.trainer import Trainer\n",
    "from utils.metrics import compute_metrics, compute_hierarchical_metrics\n",
    "from utils.visualization import (\n",
    "    plot_training_history,\n",
    "    plot_hierarchical_results,\n",
    "    plot_confusion_matrix\n",
    ")\n",
    "from config import *\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OrganMNIST3D dataset\n",
    "train_loader, val_loader, test_loader, num_classes = get_medmnist_dataloaders(\n",
    "    dataset_name='organ',\n",
    "    batch_size=DATA_CONFIG['batch_size'],\n",
    "    num_workers=DATA_CONFIG['num_workers']\n",
    ")\n",
    "\n",
    "print(f\"Total organ classes: {num_classes}\")\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "\n",
    "# Create organ-to-region mapping\n",
    "ORGAN_TO_REGION_IDX = {\n",
    "    'abdomen': 0,\n",
    "    'chest': 1,\n",
    "    \n",
    "}\n",
    "\n",
    "REGION_IDX_TO_NAME = {v: k for k, v in ORGAN_TO_REGION_IDX.items()}\n",
    "\n",
    "# Map organ classes to region indices\n",
    "organ_to_region_map = {}\n",
    "for organ_idx, organ_name in ORGAN_CLASSES.items():\n",
    "    region_name = ORGAN_TO_REGION[organ_name]\n",
    "    region_idx = ORGAN_TO_REGION_IDX[region_name]\n",
    "    organ_to_region_map[organ_idx] = region_idx\n",
    "\n",
    "print(\"\\nOrgan to Region mapping:\")\n",
    "for organ_idx, organ_name in ORGAN_CLASSES.items():\n",
    "    region_idx = organ_to_region_map[organ_idx]\n",
    "    region_name = REGION_IDX_TO_NAME[region_idx]\n",
    "    print(f\"  {organ_name:15s} -> {region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STAGE 1: Coarse Anatomical Region Classification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create coarse classifier with new architecture options\n",
    "from utils.cnn_3d_models import get_3d_model\n",
    "\n",
    "num_regions = len(ORGAN_TO_REGION_IDX)\n",
    "architecture = MODEL_CONFIG['coarse_architecture']  # Use coarse-specific architecture\n",
    "\n",
    "# Create coarse classifier\n",
    "coarse_model = CoarseAnatomicalClassifier(\n",
    "    architecture=architecture,\n",
    "    num_regions=num_regions,\n",
    "    dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
    "    region_names=REGION_IDX_TO_NAME\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"\\n Using {architecture.upper().replace('_', '-')} for Stage 1 (Coarse)\")\n",
    "print(f\"Number of anatomical regions: {num_regions}\")\n",
    "print(f\"Regions: {list(ORGAN_TO_REGION_IDX.keys())}\")\n",
    "print(f\"Region index mapping: {REGION_IDX_TO_NAME}\")\n",
    "\n",
    "# Count parameters\n",
    "coarse_params = sum(p.numel() for p in coarse_model.parameters())\n",
    "print(f\"Model parameters: {coarse_params:,}\")\n",
    "print(f\"\\n To change architecture, edit MODEL_CONFIG['coarse_architecture'] in config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3db0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data loader that converts organ labels to region labels\n",
    "class RegionDataLoader:\n",
    "    def __init__(self, data_loader, organ_to_region_map):\n",
    "        self.data_loader = data_loader\n",
    "        self.organ_to_region_map = organ_to_region_map\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for images, organ_labels in self.data_loader:\n",
    "            # Convert organ labels to region labels\n",
    "            # Flatten to 1D to handle both single and batch cases\n",
    "            organ_labels_flat = organ_labels.view(-1)\n",
    "            region_labels = torch.tensor([\n",
    "                self.organ_to_region_map[label.item()]\n",
    "                for label in organ_labels_flat\n",
    "            ]).unsqueeze(-1)\n",
    "            yield images, region_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self.data_loader.dataset\n",
    "\n",
    "# Wrap data loaders\n",
    "coarse_train_loader = RegionDataLoader(train_loader, organ_to_region_map)\n",
    "coarse_val_loader = RegionDataLoader(val_loader, organ_to_region_map)\n",
    "coarse_test_loader = RegionDataLoader(test_loader, organ_to_region_map)\n",
    "\n",
    "print(\"Region-labeled data loaders created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c94ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training for Stage 1\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.empty_cache()  # Clear GPU cache\n",
    "\n",
    "coarse_criterion = nn.CrossEntropyLoss()\n",
    "coarse_optimizer = optim.Adam(\n",
    "    coarse_model.parameters(),\n",
    "    lr=TRAINING_CONFIG['learning_rate'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
    ")\n",
    "coarse_scheduler = StepLR(\n",
    "    coarse_optimizer,\n",
    "    step_size=TRAINING_CONFIG['scheduler_step_size'],\n",
    "    gamma=TRAINING_CONFIG['scheduler_gamma']\n",
    ")\n",
    "\n",
    "coarse_trainer = Trainer(\n",
    "    model=coarse_model,\n",
    "    train_loader=coarse_train_loader,\n",
    "    val_loader=coarse_val_loader,\n",
    "    criterion=coarse_criterion,\n",
    "    optimizer=coarse_optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=coarse_scheduler\n",
    ")\n",
    "\n",
    "# Train Stage 1\n",
    "print(\"\\nTraining Stage 1: Coarse Region Classifier...\\n\")\n",
    "coarse_history = coarse_trainer.train(num_epochs=TRAINING_CONFIG['coarse_epochs'])\n",
    "\n",
    "print(\"\\nStage 1 Training Complete!\")\n",
    "print(f\"Best validation accuracy: {max(coarse_history['val_acc']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde54120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Stage 1 results\n",
    "plot_training_history(coarse_history, save_path='../figures/stage1_coarse_training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Stage 1 on test set\n",
    "from utils.metrics import evaluate_model\n",
    "\n",
    "print(\"Evaluating Stage 1 on test set...\\n\")\n",
    "coarse_test_metrics, coarse_preds, coarse_labels = evaluate_model(\n",
    "    coarse_model, coarse_test_loader, DEVICE\n",
    ")\n",
    "\n",
    "print(\"Stage 1 Test Results:\")\n",
    "print(f\"  Accuracy:  {coarse_test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {coarse_test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:    {coarse_test_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {coarse_test_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "region_names = list(ORGAN_TO_REGION_IDX.keys())\n",
    "plot_confusion_matrix(\n",
    "    coarse_test_metrics['confusion_matrix'],\n",
    "    class_names=region_names,\n",
    "    save_path='../figures/stage1_confusion_matrix.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eeb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STAGE 2: Fine Pathology Classification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create region-to-organs mapping\n",
    "region_to_organs = {'abdomen': {}, 'chest': {}}\n",
    "for organ_idx, organ_name in ORGAN_CLASSES.items():\n",
    "    region_name = ORGAN_TO_REGION[organ_name]\n",
    "    region_to_organs[region_name][organ_idx] = organ_name\n",
    "\n",
    "print(\"\\nOrgans per region:\")\n",
    "for region, organs in region_to_organs.items():\n",
    "    print(f\"  {region}: {len(organs)} organs - {list(organs.values())}\")\n",
    "\n",
    "# For Stage 2, we'll train ONE model per region that classifies organs within that region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete hierarchical model with new architectures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING FULL HIERARCHICAL MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Build region configs with actual organ counts\n",
    "region_configs = {}\n",
    "for region_name in ['abdomen', 'chest']:\n",
    "    num_organs = len(region_to_organs[region_name])\n",
    "    region_configs[region_name] = num_organs\n",
    "\n",
    "print(f\"\\nRegion configurations: {region_configs}\")\n",
    "\n",
    "# Get architectures from config\n",
    "coarse_arch = MODEL_CONFIG['coarse_architecture']\n",
    "fine_arch = MODEL_CONFIG['fine_architecture']\n",
    "\n",
    "print(f\"\\n Stage 1 (Coarse): {coarse_arch.upper().replace('_', '-')}\")\n",
    "print(f\" Stage 2 (Fine): {fine_arch.upper().replace('_', '-')}\")\n",
    "\n",
    "# Create hierarchical model with custom architectures\n",
    "hierarchical_model = HierarchicalClassificationModel(\n",
    "    region_configs=region_configs,\n",
    "    coarse_model_type=coarse_arch,\n",
    "    fine_model_type=fine_arch,\n",
    "    dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
    "    organ_to_region_map=organ_to_region_map,\n",
    "    num_total_organs=num_classes,\n",
    "    region_idx_to_name=REGION_IDX_TO_NAME\n",
    ").to(DEVICE)\n",
    "\n",
    "# Load Stage 1 weights\n",
    "hierarchical_model.coarse_classifier.model.load_state_dict(coarse_model.model.state_dict())\n",
    "print(\"\\n\u2713 Stage 1 weights loaded into hierarchical model\")\n",
    "\n",
    "# Verify the region mapping is correct\n",
    "print(f\"\u2713 Region mapping verified: {hierarchical_model.coarse_classifier.region_names}\")\n",
    "\n",
    "# Train Stage 2: Fine classifiers for each region\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Stage 2: End-to-End Hierarchical Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Freeze Stage 1 (keep coarse classifier frozen)\n",
    "for param in hierarchical_model.coarse_classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\n\u2713 Stage 1 frozen, training Stage 2 only\")\n",
    "\n",
    "# Setup training for the hierarchical model\n",
    "hierarchical_criterion = nn.CrossEntropyLoss()\n",
    "hierarchical_optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, hierarchical_model.parameters()),\n",
    "    lr=TRAINING_CONFIG['learning_rate'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "hierarchical_scheduler = StepLR(\n",
    "    hierarchical_optimizer,\n",
    "    step_size=TRAINING_CONFIG['scheduler_step_size'],\n",
    "    gamma=TRAINING_CONFIG['scheduler_gamma']\n",
    ")\n",
    "\n",
    "hierarchical_trainer = Trainer(\n",
    "    model=hierarchical_model,\n",
    "    train_loader=train_loader,  # Original organ-labeled data\n",
    "    val_loader=val_loader,\n",
    "    criterion=hierarchical_criterion,\n",
    "    optimizer=hierarchical_optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=hierarchical_scheduler\n",
    ")\n",
    "\n",
    "print(f\"\\n Training hierarchical model for {TRAINING_CONFIG['fine_epochs']} epochs...\")\n",
    "print(\"Stage 1 routes to regions, Stage 2 classifies organs within regions\\n\")\n",
    "\n",
    "hierarchical_history = hierarchical_trainer.train(num_epochs=TRAINING_CONFIG['fine_epochs'])\n",
    "\n",
    "print(\"\\n Stage 2 Training Complete!\")\n",
    "print(f\"Best hierarchical validation accuracy: {max(hierarchical_history['val_acc']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3037703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Full Hierarchical Model\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATING FULL HIERARCHICAL MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "hierarchical_model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "hierarchical_test_metrics, hierarchical_preds, hierarchical_labels = evaluate_model(\n",
    "    hierarchical_model, test_loader, DEVICE\n",
    ")\n",
    "\n",
    "print(\"\\nFull Hierarchical Model Test Results:\")\n",
    "print(f\"  Accuracy:  {hierarchical_test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {hierarchical_test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:    {hierarchical_test_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {hierarchical_test_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    hierarchical_test_metrics['confusion_matrix'],\n",
    "    class_names=list(ORGAN_CLASSES.values()),\n",
    "    save_path='../figures/hierarchical_confusion_matrix.png',\n",
    "    title='Hierarchical Model - Organ Classification'\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Full hierarchical model evaluation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hierarchical vs Stage 1 Comparison\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON: Stage 1 Only vs Full Hierarchical\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nStage 1 (Region Classification Only):\")\n",
    "print(f\"  Number of classes: {len(ORGAN_TO_REGION_IDX)}\")\n",
    "print(f\"  Test Accuracy: {coarse_test_metrics['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nFull Hierarchical (Stage 1 \u2192 Stage 2):\")\n",
    "print(f\"  Number of classes: {num_classes}\")\n",
    "print(f\"  Test Accuracy: {hierarchical_test_metrics['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n Key Insight:\")\n",
    "print(\"The hierarchical model performs end-to-end organ classification\")\n",
    "print(\"by first localizing the region (Stage 1), then classifying the\")\n",
    "print(\"specific organ within that region (Stage 2).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Hierarchical prediction on test samples\n",
    "hierarchical_model.eval()\n",
    "\n",
    "# Get a batch of test images\n",
    "test_images, test_organ_labels = next(iter(test_loader))\n",
    "test_images = test_images.to(DEVICE, dtype=torch.float32)\n",
    "if test_images.max() > 1:\n",
    "    test_images = test_images / 255.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Stage 1: Predict anatomical region\n",
    "    region_idx, region_names, region_conf = hierarchical_model.coarse_classifier.predict_region(\n",
    "        test_images\n",
    "    )\n",
    "\n",
    "print(\"Hierarchical Prediction Example:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(5, len(test_images))):\n",
    "    true_organ = ORGAN_CLASSES[test_organ_labels[i].item()]\n",
    "    pred_region = region_names[i]\n",
    "    region_confidence = region_conf[i].item()\n",
    "    true_region = ORGAN_TO_REGION[true_organ]\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  True organ: {true_organ} (region: {true_region})\")\n",
    "    print(f\"  Predicted region: {pred_region} (confidence: {region_confidence:.3f})\")\n",
    "    print(f\"  Region correct: {pred_region == true_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FULL hierarchical model\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'coarse_model_state': coarse_model.state_dict(),\n",
    "    'hierarchical_model_state': hierarchical_model.state_dict(),\n",
    "    'coarse_history': coarse_history,\n",
    "    'hierarchical_history': hierarchical_history,\n",
    "    'coarse_test_metrics': coarse_test_metrics,\n",
    "    'hierarchical_test_metrics': hierarchical_test_metrics,\n",
    "    'region_configs': region_configs,\n",
    "    'organ_to_region_map': organ_to_region_map,\n",
    "    'region_to_organs': region_to_organs,\n",
    "}, '../models/hierarchical_model.pth')\n",
    "\n",
    "print(\"\u2713 FULL Hierarchical model saved to '../models/hierarchical_model.pth'\")\n",
    "print(\"\\nSaved components:\")\n",
    "print(\"  - Stage 1 coarse classifier (region localization)\")\n",
    "print(\"  - Stage 2 fine classifiers (region-specific organ classification)\")\n",
    "print(\"  - Complete hierarchical pipeline\")\n",
    "print(\"  - Training histories and test metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935f523",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation with AUC Metrics\n",
    "\n",
    "This section implements k-fold cross-validation for both Stage 1 (coarse region classification) and the full hierarchical model, with AUC (Area Under the ROC Curve) measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e49d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import copy\n",
    "\n",
    "# Configuration for k-fold cross-validation\n",
    "K_FOLDS = 5\n",
    "KFOLD_EPOCHS_COARSE = 15  # Reduced epochs for faster k-fold\n",
    "KFOLD_EPOCHS_FINE = 20\n",
    "\n",
    "print(f\"K-Fold Cross-Validation Configuration:\")\n",
    "print(f\"  Number of folds: {K_FOLDS}\")\n",
    "print(f\"  Epochs per fold (Stage 1): {KFOLD_EPOCHS_COARSE}\")\n",
    "print(f\"  Epochs per fold (Hierarchical): {KFOLD_EPOCHS_FINE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e841b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare full dataset for k-fold (combine train + val)\n",
    "from torch.utils.data import ConcatDataset, Subset, DataLoader\n",
    "\n",
    "# Combine train and val datasets\n",
    "full_dataset = ConcatDataset([train_loader.dataset, val_loader.dataset])\n",
    "\n",
    "# Extract all labels for stratification\n",
    "all_labels = []\n",
    "for i in range(len(full_dataset)):\n",
    "    _, label = full_dataset[i]\n",
    "    all_labels.append(label.item())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(f\"Total samples for k-fold: {len(full_dataset)}\")\n",
    "print(f\"Label distribution: {np.bincount(all_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb522db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc_metrics(model, data_loader, device, num_classes, task_name=\"classification\"):\n",
    "    \"\"\"\n",
    "    Compute AUC metrics for multi-class classification.\n",
    "    Returns both macro and weighted AUC scores.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs = imgs.to(device, dtype=torch.float32)\n",
    "            if imgs.max() > 1:\n",
    "                imgs = imgs / 255.0\n",
    "            \n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Binarize labels for multi-class AUC\n",
    "    labels_binarized = label_binarize(all_labels, classes=range(num_classes))\n",
    "    \n",
    "    # Compute AUC scores\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(labels_binarized, all_probs, average='macro', multi_class='ovr')\n",
    "        auc_weighted = roc_auc_score(labels_binarized, all_probs, average='weighted', multi_class='ovr')\n",
    "    except ValueError as e:\n",
    "        print(f\"Warning: Could not compute AUC - {e}\")\n",
    "        auc_macro = 0.0\n",
    "        auc_weighted = 0.0\n",
    "    \n",
    "    # Compute per-class AUC\n",
    "    per_class_auc = []\n",
    "    for i in range(num_classes):\n",
    "        if len(np.unique(labels_binarized[:, i])) > 1:  # Check if class exists in this fold\n",
    "            try:\n",
    "                class_auc = roc_auc_score(labels_binarized[:, i], all_probs[:, i])\n",
    "                per_class_auc.append(class_auc)\n",
    "            except:\n",
    "                per_class_auc.append(0.0)\n",
    "        else:\n",
    "            per_class_auc.append(0.0)\n",
    "    \n",
    "    return {\n",
    "        'auc_macro': auc_macro,\n",
    "        'auc_weighted': auc_weighted,\n",
    "        'per_class_auc': per_class_auc,\n",
    "        'all_labels': all_labels,\n",
    "        'all_probs': all_probs\n",
    "    }\n",
    "\n",
    "print(\"\u2713 AUC computation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8050284",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation: Stage 1 (Coarse Region Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d663b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"K-FOLD CROSS-VALIDATION: STAGE 1 (COARSE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert organ labels to region labels for stratification\n",
    "region_labels = np.array([organ_to_region_map[label] for label in all_labels])\n",
    "\n",
    "# Initialize k-fold\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results for each fold\n",
    "coarse_kfold_results = {\n",
    "    'fold_accuracies': [],\n",
    "    'fold_auc_macro': [],\n",
    "    'fold_auc_weighted': [],\n",
    "    'fold_histories': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(region_labels)), region_labels)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold + 1}/{K_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create data loaders for this fold\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    \n",
    "    fold_train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=DATA_CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=DATA_CONFIG['num_workers']\n",
    "    )\n",
    "    fold_val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=DATA_CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=DATA_CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    # Wrap with region labels\n",
    "    fold_train_region_loader = RegionDataLoader(fold_train_loader, organ_to_region_map)\n",
    "    fold_val_region_loader = RegionDataLoader(fold_val_loader, organ_to_region_map)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_idx)}, Val samples: {len(val_idx)}\")\n",
    "    \n",
    "    # Create fresh model for this fold\n",
    "    fold_coarse_model = CoarseAnatomicalClassifier(\n",
    "        architecture=MODEL_CONFIG['coarse_architecture'],\n",
    "        num_regions=num_regions,\n",
    "        dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
    "        region_names=REGION_IDX_TO_NAME\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Setup optimizer and scheduler\n",
    "    fold_optimizer = optim.Adam(\n",
    "        fold_coarse_model.parameters(),\n",
    "        lr=TRAINING_CONFIG['learning_rate'],\n",
    "        weight_decay=TRAINING_CONFIG['weight_decay']\n",
    "    )\n",
    "    fold_scheduler = StepLR(\n",
    "        fold_optimizer,\n",
    "        step_size=TRAINING_CONFIG['scheduler_step_size'],\n",
    "        gamma=TRAINING_CONFIG['scheduler_gamma']\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    fold_trainer = Trainer(\n",
    "        model=fold_coarse_model,\n",
    "        train_loader=fold_train_region_loader,\n",
    "        val_loader=fold_val_region_loader,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        optimizer=fold_optimizer,\n",
    "        device=DEVICE,\n",
    "        scheduler=fold_scheduler\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    fold_history = fold_trainer.train(num_epochs=KFOLD_EPOCHS_COARSE)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_metrics, _, _ = evaluate_model(fold_coarse_model, fold_val_region_loader, DEVICE)\n",
    "    \n",
    "    # Compute AUC\n",
    "    auc_results = compute_auc_metrics(\n",
    "        fold_coarse_model,\n",
    "        fold_val_region_loader,\n",
    "        DEVICE,\n",
    "        num_regions,\n",
    "        task_name=\"coarse\"\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    coarse_kfold_results['fold_accuracies'].append(val_metrics['accuracy'])\n",
    "    coarse_kfold_results['fold_auc_macro'].append(auc_results['auc_macro'])\n",
    "    coarse_kfold_results['fold_auc_weighted'].append(auc_results['auc_weighted'])\n",
    "    coarse_kfold_results['fold_histories'].append(fold_history)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} Results:\")\n",
    "    print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  AUC (macro): {auc_results['auc_macro']:.4f}\")\n",
    "    print(f\"  AUC (weighted): {auc_results['auc_weighted']:.4f}\")\n",
    "    \n",
    "    # Clean up\n",
    "    del fold_coarse_model, fold_optimizer, fold_scheduler, fold_trainer\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()  # Clear GPU cache\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STAGE 1 K-FOLD RESULTS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {np.mean(coarse_kfold_results['fold_accuracies']):.4f} \u00b1 {np.std(coarse_kfold_results['fold_accuracies']):.4f}\")\n",
    "print(f\"AUC (macro): {np.mean(coarse_kfold_results['fold_auc_macro']):.4f} \u00b1 {np.std(coarse_kfold_results['fold_auc_macro']):.4f}\")\n",
    "print(f\"AUC (weighted): {np.mean(coarse_kfold_results['fold_auc_weighted']):.4f} \u00b1 {np.std(coarse_kfold_results['fold_auc_weighted']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d099d5",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation: Full Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42185261",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"K-FOLD CROSS-VALIDATION: HIERARCHICAL MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize k-fold with organ labels\n",
    "skf_organ = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results for each fold\n",
    "hierarchical_kfold_results = {\n",
    "    'fold_accuracies': [],\n",
    "    'fold_auc_macro': [],\n",
    "    'fold_auc_weighted': [],\n",
    "    'fold_histories': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_organ.split(np.zeros(len(all_labels)), all_labels)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold + 1}/{K_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create data loaders for this fold\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    \n",
    "    fold_train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=DATA_CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=DATA_CONFIG['num_workers']\n",
    "    )\n",
    "    fold_val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=DATA_CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=DATA_CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(train_idx)}, Val samples: {len(val_idx)}\")\n",
    "    \n",
    "    # Step 1: Train coarse classifier\n",
    "    print(f\"\\n Training Stage 1 (Coarse) for fold {fold + 1}...\")\n",
    "    \n",
    "    fold_train_region_loader = RegionDataLoader(fold_train_loader, organ_to_region_map)\n",
    "    fold_val_region_loader = RegionDataLoader(fold_val_loader, organ_to_region_map)\n",
    "    \n",
    "    fold_coarse_model = CoarseAnatomicalClassifier(\n",
    "        architecture=MODEL_CONFIG['coarse_architecture'],\n",
    "        num_regions=num_regions,\n",
    "        dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
    "        region_names=REGION_IDX_TO_NAME\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    fold_coarse_optimizer = optim.Adam(\n",
    "        fold_coarse_model.parameters(),\n",
    "        lr=TRAINING_CONFIG['learning_rate'],\n",
    "        weight_decay=TRAINING_CONFIG['weight_decay']\n",
    "    )\n",
    "    fold_coarse_scheduler = StepLR(\n",
    "        fold_coarse_optimizer,\n",
    "        step_size=TRAINING_CONFIG['scheduler_step_size'],\n",
    "        gamma=TRAINING_CONFIG['scheduler_gamma']\n",
    "    )\n",
    "    \n",
    "    fold_coarse_trainer = Trainer(\n",
    "        model=fold_coarse_model,\n",
    "        train_loader=fold_train_region_loader,\n",
    "        val_loader=fold_val_region_loader,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        optimizer=fold_coarse_optimizer,\n",
    "        device=DEVICE,\n",
    "        scheduler=fold_coarse_scheduler\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    _ = fold_coarse_trainer.train(num_epochs=KFOLD_EPOCHS_COARSE)\n",
    "    \n",
    "    # Step 2: Create and train hierarchical model\n",
    "    print(f\"\\n Training Stage 2 (Hierarchical) for fold {fold + 1}...\")\n",
    "    \n",
    "    fold_hierarchical_model = HierarchicalClassificationModel(\n",
    "        region_configs=region_configs,\n",
    "        coarse_model_type=MODEL_CONFIG['coarse_architecture'],\n",
    "        fine_model_type=MODEL_CONFIG['fine_architecture'],\n",
    "        dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
    "        organ_to_region_map=organ_to_region_map,\n",
    "        num_total_organs=num_classes,\n",
    "        region_idx_to_name=REGION_IDX_TO_NAME\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Load coarse weights\n",
    "    fold_hierarchical_model.coarse_classifier.model.load_state_dict(\n",
    "        fold_coarse_model.model.state_dict()\n",
    "    )\n",
    "    \n",
    "    # Freeze Stage 1\n",
    "    for param in fold_hierarchical_model.coarse_classifier.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Train Stage 2\n",
    "    fold_hierarchical_optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, fold_hierarchical_model.parameters()),\n",
    "        lr=TRAINING_CONFIG['learning_rate'],\n",
    "        weight_decay=TRAINING_CONFIG['weight_decay']\n",
    "    )\n",
    "    fold_hierarchical_scheduler = StepLR(\n",
    "        fold_hierarchical_optimizer,\n",
    "        step_size=TRAINING_CONFIG['scheduler_step_size'],\n",
    "        gamma=TRAINING_CONFIG['scheduler_gamma']\n",
    "    )\n",
    "    \n",
    "    fold_hierarchical_trainer = Trainer(\n",
    "        model=fold_hierarchical_model,\n",
    "        train_loader=fold_train_loader,\n",
    "        val_loader=fold_val_loader,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        optimizer=fold_hierarchical_optimizer,\n",
    "        device=DEVICE,\n",
    "        scheduler=fold_hierarchical_scheduler\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    fold_history = fold_hierarchical_trainer.train(num_epochs=KFOLD_EPOCHS_FINE)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_metrics, _, _ = evaluate_model(fold_hierarchical_model, fold_val_loader, DEVICE)\n",
    "    \n",
    "    # Compute AUC\n",
    "    auc_results = compute_auc_metrics(\n",
    "        fold_hierarchical_model,\n",
    "        fold_val_loader,\n",
    "        DEVICE,\n",
    "        num_classes,\n",
    "        task_name=\"hierarchical\"\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    hierarchical_kfold_results['fold_accuracies'].append(val_metrics['accuracy'])\n",
    "    hierarchical_kfold_results['fold_auc_macro'].append(auc_results['auc_macro'])\n",
    "    hierarchical_kfold_results['fold_auc_weighted'].append(auc_results['auc_weighted'])\n",
    "    hierarchical_kfold_results['fold_histories'].append(fold_history)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} Hierarchical Results:\")\n",
    "    print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  AUC (macro): {auc_results['auc_macro']:.4f}\")\n",
    "    print(f\"  AUC (weighted): {auc_results['auc_weighted']:.4f}\")\n",
    "    \n",
    "    # Clean up\n",
    "    del fold_coarse_model, fold_hierarchical_model\n",
    "    del fold_coarse_optimizer, fold_hierarchical_optimizer\n",
    "    del fold_coarse_scheduler, fold_hierarchical_scheduler\n",
    "    del fold_coarse_trainer, fold_hierarchical_trainer\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()  # Clear GPU cache\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"HIERARCHICAL MODEL K-FOLD RESULTS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {np.mean(hierarchical_kfold_results['fold_accuracies']):.4f} \u00b1 {np.std(hierarchical_kfold_results['fold_accuracies']):.4f}\")\n",
    "print(f\"AUC (macro): {np.mean(hierarchical_kfold_results['fold_auc_macro']):.4f} \u00b1 {np.std(hierarchical_kfold_results['fold_auc_macro']):.4f}\")\n",
    "print(f\"AUC (weighted): {np.mean(hierarchical_kfold_results['fold_auc_weighted']):.4f} \u00b1 {np.std(hierarchical_kfold_results['fold_auc_weighted']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca28613",
   "metadata": {},
   "source": [
    "## Visualize K-Fold Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot k-fold results comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Accuracy across folds\n",
    "axes[0].plot(range(1, K_FOLDS + 1), coarse_kfold_results['fold_accuracies'], \n",
    "             marker='o', label='Stage 1 (Coarse)', linewidth=2, markersize=8)\n",
    "axes[0].plot(range(1, K_FOLDS + 1), hierarchical_kfold_results['fold_accuracies'], \n",
    "             marker='s', label='Hierarchical', linewidth=2, markersize=8)\n",
    "axes[0].axhline(y=np.mean(coarse_kfold_results['fold_accuracies']), \n",
    "                color='blue', linestyle='--', alpha=0.5, label='Coarse Mean')\n",
    "axes[0].axhline(y=np.mean(hierarchical_kfold_results['fold_accuracies']), \n",
    "                color='orange', linestyle='--', alpha=0.5, label='Hierarchical Mean')\n",
    "axes[0].set_xlabel('Fold', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Accuracy Across K-Folds', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(range(1, K_FOLDS + 1))\n",
    "\n",
    "# Plot 2: AUC (macro) across folds\n",
    "axes[1].plot(range(1, K_FOLDS + 1), coarse_kfold_results['fold_auc_macro'], \n",
    "             marker='o', label='Stage 1 (Coarse)', linewidth=2, markersize=8)\n",
    "axes[1].plot(range(1, K_FOLDS + 1), hierarchical_kfold_results['fold_auc_macro'], \n",
    "             marker='s', label='Hierarchical', linewidth=2, markersize=8)\n",
    "axes[1].axhline(y=np.mean(coarse_kfold_results['fold_auc_macro']), \n",
    "                color='blue', linestyle='--', alpha=0.5, label='Coarse Mean')\n",
    "axes[1].axhline(y=np.mean(hierarchical_kfold_results['fold_auc_macro']), \n",
    "                color='orange', linestyle='--', alpha=0.5, label='Hierarchical Mean')\n",
    "axes[1].set_xlabel('Fold', fontsize=12)\n",
    "axes[1].set_ylabel('AUC (Macro)', fontsize=12)\n",
    "axes[1].set_title('AUC (Macro) Across K-Folds', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(range(1, K_FOLDS + 1))\n",
    "\n",
    "# Plot 3: AUC (weighted) across folds\n",
    "axes[2].plot(range(1, K_FOLDS + 1), coarse_kfold_results['fold_auc_weighted'], \n",
    "             marker='o', label='Stage 1 (Coarse)', linewidth=2, markersize=8)\n",
    "axes[2].plot(range(1, K_FOLDS + 1), hierarchical_kfold_results['fold_auc_weighted'], \n",
    "             marker='s', label='Hierarchical', linewidth=2, markersize=8)\n",
    "axes[2].axhline(y=np.mean(coarse_kfold_results['fold_auc_weighted']), \n",
    "                color='blue', linestyle='--', alpha=0.5, label='Coarse Mean')\n",
    "axes[2].axhline(y=np.mean(hierarchical_kfold_results['fold_auc_weighted']), \n",
    "                color='orange', linestyle='--', alpha=0.5, label='Hierarchical Mean')\n",
    "axes[2].set_xlabel('Fold', fontsize=12)\n",
    "axes[2].set_ylabel('AUC (Weighted)', fontsize=12)\n",
    "axes[2].set_title('AUC (Weighted) Across K-Folds', fontsize=14, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_xticks(range(1, K_FOLDS + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/kfold_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 K-fold comparison plot saved to '../figures/kfold_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "import pandas as pd\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': ['Accuracy', 'AUC (Macro)', 'AUC (Weighted)'],\n",
    "    'Stage 1 Mean': [\n",
    "        f\"{np.mean(coarse_kfold_results['fold_accuracies']):.4f}\",\n",
    "        f\"{np.mean(coarse_kfold_results['fold_auc_macro']):.4f}\",\n",
    "        f\"{np.mean(coarse_kfold_results['fold_auc_weighted']):.4f}\"\n",
    "    ],\n",
    "    'Stage 1 Std': [\n",
    "        f\"{np.std(coarse_kfold_results['fold_accuracies']):.4f}\",\n",
    "        f\"{np.std(coarse_kfold_results['fold_auc_macro']):.4f}\",\n",
    "        f\"{np.std(coarse_kfold_results['fold_auc_weighted']):.4f}\"\n",
    "    ],\n",
    "    'Hierarchical Mean': [\n",
    "        f\"{np.mean(hierarchical_kfold_results['fold_accuracies']):.4f}\",\n",
    "        f\"{np.mean(hierarchical_kfold_results['fold_auc_macro']):.4f}\",\n",
    "        f\"{np.mean(hierarchical_kfold_results['fold_auc_weighted']):.4f}\"\n",
    "    ],\n",
    "    'Hierarchical Std': [\n",
    "        f\"{np.std(hierarchical_kfold_results['fold_accuracies']):.4f}\",\n",
    "        f\"{np.std(hierarchical_kfold_results['fold_auc_macro']):.4f}\",\n",
    "        f\"{np.std(hierarchical_kfold_results['fold_auc_weighted']):.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "kfold_save_path = '../models/kfold_results.pth'\n",
    "\n",
    "torch.save({\n",
    "    'coarse_kfold_results': coarse_kfold_results,\n",
    "    'hierarchical_kfold_results': hierarchical_kfold_results,\n",
    "    'k_folds': K_FOLDS,\n",
    "    'kfold_epochs_coarse': KFOLD_EPOCHS_COARSE,\n",
    "    'kfold_epochs_fine': KFOLD_EPOCHS_FINE,\n",
    "    'summary_df': summary_df\n",
    "}, kfold_save_path)\n",
    "\n",
    "print(f\"\u2713 K-fold results saved to '{kfold_save_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}