{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hierarchical Classification - Stage 2: Fine Pathology Training\n",
                "\n",
                "This notebook trains **Stage 2 (Fine Classifiers)** of the hierarchical classification model.\n",
                "\n",
                "## Prerequisites\n",
                "- Run `03a_stage1_coarse_training.ipynb` first to train and save the coarse classifier\n",
                "\n",
                "## Training Pipeline\n",
                "- **Stage 1 (Previous Notebook)**: Pre-trained coarse classifier (anatomical regions)\n",
                "- **Stage 2 (This Notebook)**: Load Stage 1 weights, train entire model **end-to-end**\n",
                "\n",
                "## End-to-End Training (NO FREEZING)\n",
                "Unlike traditional transfer learning where early layers are frozen, we train the entire model together. This allows the shared backbone to adapt its representations for the fine-grained pathology classification task.\n",
                "\n",
                "## Fine Classifiers\n",
                "- **Abdomen**: Organ classification\n",
                "- **Chest**: Nodule and fracture classification\n",
                "- **Brain**: Vessel classification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GPU detected: NVIDIA GeForce RTX 3070\n",
                        "GPU memory: 8.21 GB\n",
                        "Platform: NVIDIA CUDA\n",
                        "Device: cuda\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import os\n",
                "import json\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm\n",
                "\n",
                "from config import (\n",
                "    DEVICE, DATA_CONFIG, MODEL_CONFIG, TRAINING_CONFIG,\n",
                "    PATHS, set_seed, DEFAULT_MERGED_DATASETS\n",
                ")\n",
                "from utils.data_loader import create_hierarchical_dataset\n",
                "from utils.hierarchical_model import HierarchicalClassificationModel\n",
                "\n",
                "set_seed(42)\n",
                "print(f\"Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Stage 1 Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Stage 1 Information:\n",
                        "  Model path: /home/luca/HierarchicalMIC/models/stage1_coarse_efficientnet3d_b0.pth\n",
                        "  Architecture: efficientnet3d_b0\n",
                        "  Coarse Test Accuracy: 0.9549\n",
                        "  Best Val Accuracy: 0.9861\n"
                    ]
                }
            ],
            "source": [
                "# Load Stage 1 information\n",
                "stage1_info_path = f\"{PATHS['models']}/stage1_info_{MODEL_CONFIG['architecture']}.json\"\n",
                "\n",
                "if not os.path.exists(stage1_info_path):\n",
                "    raise FileNotFoundError(\n",
                "        f\"Stage 1 info file not found at {stage1_info_path}. \"\n",
                "        \"Please run 03a_stage1_coarse_training.ipynb first.\"\n",
                "    )\n",
                "\n",
                "with open(stage1_info_path, 'r') as f:\n",
                "    stage1_info = json.load(f)\n",
                "\n",
                "print(\"Stage 1 Information:\")\n",
                "print(f\"  Model path: {stage1_info['model_path']}\")\n",
                "print(f\"  Architecture: {stage1_info['architecture']}\")\n",
                "print(f\"  Coarse Test Accuracy: {stage1_info['test_accuracy']:.4f}\")\n",
                "print(f\"  Best Val Accuracy: {stage1_info['best_val_accuracy']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Merged Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading datasets: ['organ', 'nodule', 'adrenal', 'fracture', 'vessel']\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/organmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/nodulemnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/adrenalmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/fracturemnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/vesselmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/organmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/nodulemnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/adrenalmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/fracturemnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/vesselmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/organmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/nodulemnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/adrenalmnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/fracturemnist3d.npz\n",
                        "Using downloaded and verified file: /home/luca/.medmnist/vesselmnist3d.npz\n",
                        "\n",
                        "============================================================\n",
                        "MERGED DATASET INFO\n",
                        "============================================================\n",
                        "Datasets: ['organ', 'nodule', 'adrenal', 'fracture', 'vessel']\n",
                        "Train samples: 5,679\n",
                        "Val samples: 718\n",
                        "Test samples: 1,840\n",
                        "\n",
                        "Coarse classes (regions): 3\n",
                        "Region mapping: {0: 'abdomen', 1: 'chest', 2: 'brain'}\n",
                        "Fine classes: 10\n"
                    ]
                }
            ],
            "source": [
                "# Load all 5 merged datasets\n",
                "print(f\"Loading datasets: {DEFAULT_MERGED_DATASETS}\")\n",
                "\n",
                "train_loader, val_loader, test_loader, dataset_info = create_hierarchical_dataset(\n",
                "    datasets_to_include=DEFAULT_MERGED_DATASETS,\n",
                "    batch_size=DATA_CONFIG['batch_size'],\n",
                "    num_workers=DATA_CONFIG['num_workers']\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"MERGED DATASET INFO\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Datasets: {dataset_info['datasets_included']}\")\n",
                "print(f\"Train samples: {dataset_info['train_samples']:,}\")\n",
                "print(f\"Val samples: {dataset_info['val_samples']:,}\")\n",
                "print(f\"Test samples: {dataset_info['test_samples']:,}\")\n",
                "print(f\"\\nCoarse classes (regions): {dataset_info['num_coarse_classes']}\")\n",
                "print(f\"Region mapping: {dataset_info['idx_to_region']}\")\n",
                "print(f\"Fine classes: {dataset_info['num_fine_classes']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Region configurations:\n",
                        "  abdomen: 10 classes\n",
                        "  chest: 8 classes\n",
                        "  brain: 2 classes\n"
                    ]
                }
            ],
            "source": [
                "# Configure region-specific classes\n",
                "region_configs = dataset_info['region_num_classes']\n",
                "region_idx_to_name = dataset_info['idx_to_region']\n",
                "\n",
                "print(\"Region configurations:\")\n",
                "for region, num_classes in region_configs.items():\n",
                "    print(f\"  {region}: {num_classes} classes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build and Load Hierarchical Model with Stage 1 Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Loaded Stage 1 weights from: /home/luca/HierarchicalMIC/models/stage1_coarse_efficientnet3d_b0.pth\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_7469/1499373810.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
                        "  model.load_state_dict(torch.load(stage1_path))\n"
                    ]
                }
            ],
            "source": [
                "# Create hierarchical model\n",
                "model = HierarchicalClassificationModel(\n",
                "    region_configs=region_configs,\n",
                "    architecture=MODEL_CONFIG['architecture'],\n",
                "    coarse_model_type=MODEL_CONFIG['coarse_architecture'],\n",
                "    fine_model_type=MODEL_CONFIG['fine_architecture'],\n",
                "    dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
                "    region_idx_to_name=region_idx_to_name,\n",
                "    num_total_organs=dataset_info['num_fine_classes'],\n",
                "    use_subtypes=False\n",
                ").to(DEVICE)\n",
                "\n",
                "# Load Stage 1 weights\n",
                "stage1_path = stage1_info['model_path']\n",
                "if not os.path.exists(stage1_path):\n",
                "    raise FileNotFoundError(\n",
                "        f\"Stage 1 model not found at {stage1_path}. \"\n",
                "        \"Please run 03a_stage1_coarse_training.ipynb first.\"\n",
                "    )\n",
                "\n",
                "model.load_state_dict(torch.load(stage1_path))\n",
                "print(f\"\\nLoaded Stage 1 weights from: {stage1_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "End-to-End Training Mode (NO FREEZING)\n",
                        "Both Stage 1 (Coarse) and Stage 2 (Fine) classifiers will be trained together.\n",
                        "\n",
                        "Model configuration:\n",
                        "  Total parameters: 4,851,479\n",
                        "  Trainable parameters: 4,851,479\n",
                        "  Coarse architecture: efficientnet3d_b0\n",
                        "  Fine architecture: efficientnet3d_b0\n"
                    ]
                }
            ],
            "source": [
                "# End-to-End Training: All parameters are trainable!\n",
                "print(\"\\nEnd-to-End Training Mode (NO FREEZING)\")\n",
                "print(\"Both Stage 1 (Coarse) and Stage 2 (Fine) classifiers will be trained together.\")\n",
                "\n",
                "# Count parameters - all should be trainable\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "\n",
                "print(f\"\\nModel configuration:\")\n",
                "print(f\"  Total parameters: {total_params:,}\")\n",
                "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
                "print(f\"  Coarse architecture: {MODEL_CONFIG['coarse_architecture']}\")\n",
                "print(f\"  Fine architecture: {MODEL_CONFIG['fine_architecture']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. End-to-End Training: Coarse + Fine Classifiers\n",
                "\n",
                "This stage trains the entire hierarchical model end-to-end. Both the coarse classifier (from Stage 1) and the fine classifiers are trained together, allowing the shared backbone to adapt for the fine-grained pathology task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_stage2(model, train_loader, val_loader, device, epochs, lr, region_idx_to_name):\n",
                "    \"\"\"Train entire hierarchical model end-to-end (no freezing).\"\"\"\n",
                "    \n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    \n",
                "    # Optimize ALL model parameters (end-to-end training)\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
                "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
                "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
                "    )\n",
                "    \n",
                "    history = {\n",
                "        'train_loss': [],\n",
                "        'train_acc': [],\n",
                "        'val_loss': [],\n",
                "        'val_acc': [],\n",
                "        'coarse_train_acc': [],\n",
                "        'coarse_val_acc': [],\n",
                "        'region_train_acc': {name: [] for name in region_idx_to_name.values()},\n",
                "        'region_val_acc': {name: [] for name in region_idx_to_name.values()}\n",
                "    }\n",
                "    \n",
                "    best_val_acc = 0.0\n",
                "    \n",
                "    print(\"\\n=== End-to-End Training: Coarse + Fine Classifiers ===\")\n",
                "    print(\"(All parameters are trainable)\\n\")\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        train_loss = 0.0\n",
                "        \n",
                "        # Tracking for coarse accuracy\n",
                "        coarse_correct = 0\n",
                "        coarse_total = 0\n",
                "        \n",
                "        region_correct = {name: 0 for name in region_idx_to_name.values()}\n",
                "        region_total = {name: 0 for name in region_idx_to_name.values()}\n",
                "        \n",
                "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
                "        for imgs, coarse_labels, fine_labels in pbar:\n",
                "            imgs = imgs.to(device, dtype=torch.float32)\n",
                "            if imgs.max() > 1:\n",
                "                imgs = imgs / 255.0\n",
                "            coarse_labels = coarse_labels.long().to(device)\n",
                "            fine_labels = fine_labels.long().to(device)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            batch_loss = 0.0\n",
                "            \n",
                "            # Also train coarse classifier (end-to-end)\n",
                "            coarse_logits = model.forward_coarse(imgs)\n",
                "            coarse_loss = criterion(coarse_logits, coarse_labels)\n",
                "            batch_loss = batch_loss + coarse_loss\n",
                "            \n",
                "            # Track coarse accuracy\n",
                "            coarse_preds = coarse_logits.argmax(1)\n",
                "            coarse_correct += (coarse_preds == coarse_labels).sum().item()\n",
                "            coarse_total += imgs.size(0)\n",
                "            \n",
                "            # Train each region's fine classifier\n",
                "            for region_idx, region_name in region_idx_to_name.items():\n",
                "                mask = (coarse_labels == region_idx)\n",
                "                if not mask.any():\n",
                "                    continue\n",
                "                \n",
                "                region_imgs = imgs[mask]\n",
                "                region_fine_labels = fine_labels[mask]\n",
                "                \n",
                "                fine_logits = model.forward_fine(region_imgs, region_name)\n",
                "                loss = criterion(fine_logits, region_fine_labels)\n",
                "                batch_loss = batch_loss + loss\n",
                "                \n",
                "                preds = fine_logits.argmax(1)\n",
                "                region_correct[region_name] += (preds == region_fine_labels).sum().item()\n",
                "                region_total[region_name] += region_imgs.size(0)\n",
                "            \n",
                "            if isinstance(batch_loss, float) and batch_loss == 0.0:\n",
                "                continue\n",
                "            \n",
                "            batch_loss.backward()\n",
                "            optimizer.step()\n",
                "            train_loss += batch_loss.item()\n",
                "        \n",
                "        # Compute training metrics\n",
                "        avg_train_loss = train_loss / len(train_loader)\n",
                "        total_correct = sum(region_correct.values())\n",
                "        total_samples = sum(region_total.values())\n",
                "        train_acc = total_correct / total_samples if total_samples > 0 else 0\n",
                "        coarse_train_acc = coarse_correct / coarse_total if coarse_total > 0 else 0\n",
                "        \n",
                "        history['train_loss'].append(avg_train_loss)\n",
                "        history['train_acc'].append(train_acc)\n",
                "        history['coarse_train_acc'].append(coarse_train_acc)\n",
                "        \n",
                "        for region_name in region_idx_to_name.values():\n",
                "            if region_total[region_name] > 0:\n",
                "                acc = region_correct[region_name] / region_total[region_name]\n",
                "            else:\n",
                "                acc = 0.0\n",
                "            history['region_train_acc'][region_name].append(acc)\n",
                "        \n",
                "        # Validation\n",
                "        model.eval()\n",
                "        val_loss = 0.0\n",
                "        val_coarse_correct = 0\n",
                "        val_coarse_total = 0\n",
                "        val_region_correct = {name: 0 for name in region_idx_to_name.values()}\n",
                "        val_region_total = {name: 0 for name in region_idx_to_name.values()}\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            for imgs, coarse_labels, fine_labels in val_loader:\n",
                "                imgs = imgs.to(device, dtype=torch.float32)\n",
                "                if imgs.max() > 1:\n",
                "                    imgs = imgs / 255.0\n",
                "                coarse_labels = coarse_labels.long().to(device)\n",
                "                fine_labels = fine_labels.long().to(device)\n",
                "                \n",
                "                # Coarse validation\n",
                "                coarse_logits = model.forward_coarse(imgs)\n",
                "                coarse_loss = criterion(coarse_logits, coarse_labels)\n",
                "                val_loss += coarse_loss.item()\n",
                "                \n",
                "                coarse_preds = coarse_logits.argmax(1)\n",
                "                val_coarse_correct += (coarse_preds == coarse_labels).sum().item()\n",
                "                val_coarse_total += imgs.size(0)\n",
                "                \n",
                "                # Fine validation per region\n",
                "                for region_idx, region_name in region_idx_to_name.items():\n",
                "                    mask = (coarse_labels == region_idx)\n",
                "                    if not mask.any():\n",
                "                        continue\n",
                "                    \n",
                "                    region_imgs = imgs[mask]\n",
                "                    region_fine_labels = fine_labels[mask]\n",
                "                    \n",
                "                    fine_logits = model.forward_fine(region_imgs, region_name)\n",
                "                    loss = criterion(fine_logits, region_fine_labels)\n",
                "                    val_loss += loss.item()\n",
                "                    \n",
                "                    preds = fine_logits.argmax(1)\n",
                "                    val_region_correct[region_name] += (preds == region_fine_labels).sum().item()\n",
                "                    val_region_total[region_name] += region_imgs.size(0)\n",
                "        \n",
                "        avg_val_loss = val_loss / len(val_loader)\n",
                "        val_total_correct = sum(val_region_correct.values())\n",
                "        val_total_samples = sum(val_region_total.values())\n",
                "        val_acc = val_total_correct / val_total_samples if val_total_samples > 0 else 0\n",
                "        val_coarse_acc = val_coarse_correct / val_coarse_total if val_coarse_total > 0 else 0\n",
                "        \n",
                "        history['val_loss'].append(avg_val_loss)\n",
                "        history['val_acc'].append(val_acc)\n",
                "        history['coarse_val_acc'].append(val_coarse_acc)\n",
                "        \n",
                "        for region_name in region_idx_to_name.values():\n",
                "            if val_region_total[region_name] > 0:\n",
                "                acc = val_region_correct[region_name] / val_region_total[region_name]\n",
                "            else:\n",
                "                acc = 0.0\n",
                "            history['region_val_acc'][region_name].append(acc)\n",
                "        \n",
                "        scheduler.step(avg_val_loss)\n",
                "        \n",
                "        print(f\"Epoch {epoch+1} Results:\")\n",
                "        print(f\"  Coarse: Train Acc={coarse_train_acc:.4f}, Val Acc={val_coarse_acc:.4f}\")\n",
                "        for region_name in region_idx_to_name.values():\n",
                "            train_r_acc = history['region_train_acc'][region_name][-1]\n",
                "            val_r_acc = history['region_val_acc'][region_name][-1]\n",
                "            print(f\"  {region_name}: Train Acc={train_r_acc:.4f}, Val Acc={val_r_acc:.4f}\")\n",
                "        print(f\"  Overall: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
                "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
                "        \n",
                "        # Save best model\n",
                "        if val_acc > best_val_acc:\n",
                "            best_val_acc = val_acc\n",
                "            torch.save(model.state_dict(), \n",
                "                       f\"{PATHS['models']}/hierarchical_model_{MODEL_CONFIG['architecture']}.pth\")\n",
                "            print(f\"  -> New best model saved (Val Acc: {best_val_acc:.4f})\")\n",
                "        print()\n",
                "    \n",
                "    print(f\"\\nEnd-to-End Training Complete! Best Val Acc: {best_val_acc:.4f}\")\n",
                "    return history, best_val_acc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training configuration:\n",
                        "  Fine epochs: 30\n",
                        "  Learning rate: 0.001\n"
                    ]
                }
            ],
            "source": [
                "# Training configuration\n",
                "print(f\"Training configuration:\")\n",
                "print(f\"  Fine epochs: {TRAINING_CONFIG['fine_epochs']}\")\n",
                "print(f\"  Learning rate: {TRAINING_CONFIG['learning_rate']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/luca/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== End-to-End Training: Coarse + Fine Classifiers ===\n",
                        "(All parameters are trainable)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1: 100%|██████████| 710/710 [00:41<00:00, 17.11it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1 Results:\n",
                        "  Coarse: Train Acc=0.9468, Val Acc=0.9638\n",
                        "  abdomen: Train Acc=0.4553, Val Acc=0.4155\n",
                        "  chest: Train Acc=0.4554, Val Acc=0.5065\n",
                        "  brain: Train Acc=0.8644, Val Acc=0.8848\n",
                        "  Overall: Train Loss=3.6591, Train Acc=0.5515, Val Loss=1.9193, Val Acc=0.5794\n",
                        "  -> New best model saved (Val Acc: 0.5794)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 2: 100%|██████████| 710/710 [00:42<00:00, 16.57it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 2 Results:\n",
                        "  Coarse: Train Acc=0.9567, Val Acc=0.9763\n",
                        "  abdomen: Train Acc=0.5121, Val Acc=0.4155\n",
                        "  chest: Train Acc=0.4805, Val Acc=0.5292\n",
                        "  brain: Train Acc=0.8794, Val Acc=0.8848\n",
                        "  Overall: Train Loss=3.1137, Train Acc=0.5853, Val Loss=2.1820, Val Acc=0.5891\n",
                        "  -> New best model saved (Val Acc: 0.5891)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 3: 100%|██████████| 710/710 [00:41<00:00, 16.95it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 3 Results:\n",
                        "  Coarse: Train Acc=0.9532, Val Acc=0.9485\n",
                        "  abdomen: Train Acc=0.5030, Val Acc=0.4201\n",
                        "  chest: Train Acc=0.5187, Val Acc=0.5649\n",
                        "  brain: Train Acc=0.8779, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.9514, Train Acc=0.5976, Val Loss=1.5325, Val Acc=0.6058\n",
                        "  -> New best model saved (Val Acc: 0.6058)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 4: 100%|██████████| 710/710 [00:40<00:00, 17.67it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 4 Results:\n",
                        "  Coarse: Train Acc=0.9546, Val Acc=0.9540\n",
                        "  abdomen: Train Acc=0.5186, Val Acc=0.4475\n",
                        "  chest: Train Acc=0.4992, Val Acc=0.5617\n",
                        "  brain: Train Acc=0.8801, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.9359, Train Acc=0.5955, Val Loss=1.4873, Val Acc=0.6128\n",
                        "  -> New best model saved (Val Acc: 0.6128)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 5: 100%|██████████| 710/710 [00:42<00:00, 16.66it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 5 Results:\n",
                        "  Coarse: Train Acc=0.9604, Val Acc=0.9749\n",
                        "  abdomen: Train Acc=0.5231, Val Acc=0.4201\n",
                        "  chest: Train Acc=0.5153, Val Acc=0.2857\n",
                        "  brain: Train Acc=0.8667, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.8204, Train Acc=0.6006, Val Loss=1.5230, Val Acc=0.4861\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 6: 100%|██████████| 710/710 [00:42<00:00, 16.56it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 6 Results:\n",
                        "  Coarse: Train Acc=0.9604, Val Acc=0.9220\n",
                        "  abdomen: Train Acc=0.5161, Val Acc=0.1735\n",
                        "  chest: Train Acc=0.5038, Val Acc=0.1396\n",
                        "  brain: Train Acc=0.8861, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.8303, Train Acc=0.5980, Val Loss=2.4191, Val Acc=0.3482\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 7: 100%|██████████| 710/710 [00:42<00:00, 16.56it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 7 Results:\n",
                        "  Coarse: Train Acc=0.9627, Val Acc=0.9749\n",
                        "  abdomen: Train Acc=0.5206, Val Acc=0.1826\n",
                        "  chest: Train Acc=0.4928, Val Acc=0.4513\n",
                        "  brain: Train Acc=0.8764, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.8278, Train Acc=0.5927, Val Loss=1.5684, Val Acc=0.4847\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 8: 100%|██████████| 710/710 [00:41<00:00, 17.19it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 8 Results:\n",
                        "  Coarse: Train Acc=0.9665, Val Acc=0.9777\n",
                        "  abdomen: Train Acc=0.5271, Val Acc=0.4703\n",
                        "  chest: Train Acc=0.5276, Val Acc=0.6039\n",
                        "  brain: Train Acc=0.8861, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.7153, Train Acc=0.6117, Val Loss=1.3322, Val Acc=0.6379\n",
                        "  -> New best model saved (Val Acc: 0.6379)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 9: 100%|██████████| 710/710 [00:41<00:00, 16.96it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 9 Results:\n",
                        "  Coarse: Train Acc=0.9641, Val Acc=0.9861\n",
                        "  abdomen: Train Acc=0.5111, Val Acc=0.4475\n",
                        "  chest: Train Acc=0.5336, Val Acc=0.5519\n",
                        "  brain: Train Acc=0.8749, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.7181, Train Acc=0.6059, Val Loss=1.3844, Val Acc=0.6086\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 10: 100%|██████████| 710/710 [00:38<00:00, 18.59it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 10 Results:\n",
                        "  Coarse: Train Acc=0.9613, Val Acc=0.9875\n",
                        "  abdomen: Train Acc=0.5281, Val Acc=0.4658\n",
                        "  chest: Train Acc=0.5085, Val Acc=0.5325\n",
                        "  brain: Train Acc=0.8697, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.9719, Train Acc=0.6003, Val Loss=2.1235, Val Acc=0.6058\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 11: 100%|██████████| 710/710 [00:42<00:00, 16.67it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 11 Results:\n",
                        "  Coarse: Train Acc=0.9639, Val Acc=0.9721\n",
                        "  abdomen: Train Acc=0.5342, Val Acc=0.4201\n",
                        "  chest: Train Acc=0.5195, Val Acc=0.5487\n",
                        "  brain: Train Acc=0.8839, Val Acc=0.8691\n",
                        "  Overall: Train Loss=2.7311, Train Acc=0.6103, Val Loss=1.5647, Val Acc=0.5947\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 12: 100%|██████████| 710/710 [00:41<00:00, 17.29it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 12 Results:\n",
                        "  Coarse: Train Acc=0.9644, Val Acc=0.9889\n",
                        "  abdomen: Train Acc=0.5332, Val Acc=0.5068\n",
                        "  chest: Train Acc=0.5289, Val Acc=0.5714\n",
                        "  brain: Train Acc=0.8869, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.6395, Train Acc=0.6145, Val Loss=1.7699, Val Acc=0.6351\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 13: 100%|██████████| 710/710 [00:41<00:00, 17.05it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 13 Results:\n",
                        "  Coarse: Train Acc=0.9732, Val Acc=0.9749\n",
                        "  abdomen: Train Acc=0.5608, Val Acc=0.4840\n",
                        "  chest: Train Acc=0.5272, Val Acc=0.5682\n",
                        "  brain: Train Acc=0.8869, Val Acc=0.8848\n",
                        "  Overall: Train Loss=2.5177, Train Acc=0.6235, Val Loss=1.2905, Val Acc=0.6267\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 14:  17%|█▋        | 118/710 [00:07<00:36, 16.14it/s]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train Stage 2 (End-to-End)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history, best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_stage2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregion_idx_to_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion_idx_to_name\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE 2 END-TO-END TRAINING COMPLETE!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[7], line 51\u001b[0m, in \u001b[0;36mtrain_stage2\u001b[0;34m(model, train_loader, val_loader, device, epochs, lr, region_idx_to_name)\u001b[0m\n\u001b[1;32m     48\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Also train coarse classifier (end-to-end)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m coarse_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_coarse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m coarse_loss \u001b[38;5;241m=\u001b[39m criterion(coarse_logits, coarse_labels)\n\u001b[1;32m     53\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m batch_loss \u001b[38;5;241m+\u001b[39m coarse_loss\n",
                        "File \u001b[0;32m~/HierarchicalMIC/notebooks/../utils/hierarchical_model.py:104\u001b[0m, in \u001b[0;36mHierarchicalClassificationModel.forward_coarse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_coarse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stage 1: Predict anatomical region.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoarse_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/HierarchicalMIC/notebooks/../utils/coarse_classifier.py:73\u001b[0m, in \u001b[0;36mCoarseAnatomicalClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Forward pass to classify anatomical region.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        torch.Tensor: Logits for each anatomical region\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/HierarchicalMIC/notebooks/../utils/cnn_3d_models.py:564\u001b[0m, in \u001b[0;36mEfficientNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_sample:\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 564\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_final(x)\n\u001b[1;32m    566\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/HierarchicalMIC/notebooks/../utils/cnn_3d_models.py:467\u001b[0m, in \u001b[0;36mMBConv3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_residual:\n\u001b[0;32m--> 467\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.pyenv/versions/3.12.11/lib/python3.12/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Train Stage 2 (End-to-End)\n",
                "history, best_val_acc = train_stage2(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    device=DEVICE,\n",
                "    epochs=TRAINING_CONFIG['fine_epochs'],\n",
                "    lr=TRAINING_CONFIG['learning_rate'],\n",
                "    region_idx_to_name=region_idx_to_name\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"STAGE 2 END-TO-END TRAINING COMPLETE!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
                "print(f\"Full model saved to: {PATHS['models']}/hierarchical_model_{MODEL_CONFIG['architecture']}.pth\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "\n",
                "# Overall Loss\n",
                "axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
                "axes[0, 0].plot(history['val_loss'], label='Val Loss', color='orange')\n",
                "axes[0, 0].set_xlabel('Epoch')\n",
                "axes[0, 0].set_ylabel('Loss')\n",
                "axes[0, 0].set_title('End-to-End Training: Combined Loss')\n",
                "axes[0, 0].legend()\n",
                "axes[0, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# Overall Fine Accuracy\n",
                "axes[0, 1].plot(history['train_acc'], label='Train Acc', color='blue')\n",
                "axes[0, 1].plot(history['val_acc'], label='Val Acc', color='orange')\n",
                "axes[0, 1].set_xlabel('Epoch')\n",
                "axes[0, 1].set_ylabel('Accuracy')\n",
                "axes[0, 1].set_title('Stage 2: Fine Classifier Accuracy')\n",
                "axes[0, 1].legend()\n",
                "axes[0, 1].grid(True, alpha=0.3)\n",
                "\n",
                "# Coarse Accuracy (Now also tracked during Stage 2!)\n",
                "axes[0, 2].plot(history['coarse_train_acc'], label='Train Acc', color='blue')\n",
                "axes[0, 2].plot(history['coarse_val_acc'], label='Val Acc', color='orange')\n",
                "axes[0, 2].set_xlabel('Epoch')\n",
                "axes[0, 2].set_ylabel('Accuracy')\n",
                "axes[0, 2].set_title('Stage 1: Coarse Classifier Accuracy (during Stage 2)')\n",
                "axes[0, 2].legend()\n",
                "axes[0, 2].grid(True, alpha=0.3)\n",
                "\n",
                "# Per-region training accuracy\n",
                "colors = ['red', 'green', 'purple']\n",
                "for i, (region_name, accs) in enumerate(history['region_train_acc'].items()):\n",
                "    axes[1, 0].plot(accs, label=f'{region_name} (train)', color=colors[i % len(colors)])\n",
                "axes[1, 0].set_xlabel('Epoch')\n",
                "axes[1, 0].set_ylabel('Accuracy')\n",
                "axes[1, 0].set_title('Stage 2: Per-Region Training Accuracy')\n",
                "axes[1, 0].legend()\n",
                "axes[1, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# Per-region validation accuracy\n",
                "for i, (region_name, accs) in enumerate(history['region_val_acc'].items()):\n",
                "    axes[1, 1].plot(accs, label=f'{region_name} (val)', color=colors[i % len(colors)])\n",
                "axes[1, 1].set_xlabel('Epoch')\n",
                "axes[1, 1].set_ylabel('Accuracy')\n",
                "axes[1, 1].set_title('Stage 2: Per-Region Validation Accuracy')\n",
                "axes[1, 1].legend()\n",
                "axes[1, 1].grid(True, alpha=0.3)\n",
                "\n",
                "# Combined comparison\n",
                "axes[1, 2].plot(history['coarse_val_acc'], label='Coarse Val', color='blue', linestyle='--')\n",
                "axes[1, 2].plot(history['val_acc'], label='Fine Val', color='orange', linestyle='-')\n",
                "axes[1, 2].set_xlabel('Epoch')\n",
                "axes[1, 2].set_ylabel('Accuracy')\n",
                "axes[1, 2].set_title('Coarse vs Fine Validation Accuracy')\n",
                "axes[1, 2].legend()\n",
                "axes[1, 2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{PATHS['figures']}/stage2_fine_training_{MODEL_CONFIG['architecture']}.png\", dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Full Hierarchical Evaluation on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_hierarchical_model(model, test_loader, device, region_idx_to_name):\n",
                "    \"\"\"Evaluate hierarchical model on test set.\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    coarse_correct = 0\n",
                "    coarse_total = 0\n",
                "    \n",
                "    fine_correct = {name: 0 for name in region_idx_to_name.values()}\n",
                "    fine_total = {name: 0 for name in region_idx_to_name.values()}\n",
                "    \n",
                "    all_coarse_preds = []\n",
                "    all_coarse_labels = []\n",
                "    all_fine_preds = []\n",
                "    all_fine_labels = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for imgs, coarse_labels, fine_labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
                "            imgs = imgs.to(device, dtype=torch.float32)\n",
                "            if imgs.max() > 1:\n",
                "                imgs = imgs / 255.0\n",
                "            \n",
                "            coarse_labels = coarse_labels.long().to(device)\n",
                "            fine_labels = fine_labels.long().to(device)\n",
                "            \n",
                "            # Stage 1: Coarse prediction\n",
                "            coarse_logits = model.forward_coarse(imgs)\n",
                "            coarse_preds = coarse_logits.argmax(1)\n",
                "            \n",
                "            coarse_correct += (coarse_preds == coarse_labels).sum().item()\n",
                "            coarse_total += imgs.size(0)\n",
                "            \n",
                "            all_coarse_preds.extend(coarse_preds.cpu().numpy())\n",
                "            all_coarse_labels.extend(coarse_labels.cpu().numpy())\n",
                "            \n",
                "            # Stage 2: Fine prediction per region\n",
                "            for region_idx, region_name in region_idx_to_name.items():\n",
                "                mask = (coarse_labels == region_idx)\n",
                "                if not mask.any():\n",
                "                    continue\n",
                "                \n",
                "                region_imgs = imgs[mask]\n",
                "                region_fine_labels = fine_labels[mask]\n",
                "                \n",
                "                fine_logits = model.forward_fine(region_imgs, region_name)\n",
                "                fine_preds = fine_logits.argmax(1)\n",
                "                \n",
                "                fine_correct[region_name] += (fine_preds == region_fine_labels).sum().item()\n",
                "                fine_total[region_name] += region_imgs.size(0)\n",
                "                \n",
                "                all_fine_preds.extend(fine_preds.cpu().numpy())\n",
                "                all_fine_labels.extend(region_fine_labels.cpu().numpy())\n",
                "    \n",
                "    # Compute metrics\n",
                "    coarse_acc = coarse_correct / coarse_total if coarse_total > 0 else 0\n",
                "    \n",
                "    fine_acc_per_region = {}\n",
                "    for region_name in region_idx_to_name.values():\n",
                "        if fine_total[region_name] > 0:\n",
                "            fine_acc_per_region[region_name] = fine_correct[region_name] / fine_total[region_name]\n",
                "        else:\n",
                "            fine_acc_per_region[region_name] = 0.0\n",
                "    \n",
                "    overall_fine_acc = sum(fine_correct.values()) / sum(fine_total.values()) if sum(fine_total.values()) > 0 else 0\n",
                "    \n",
                "    return {\n",
                "        'coarse_accuracy': coarse_acc,\n",
                "        'fine_accuracy_per_region': fine_acc_per_region,\n",
                "        'overall_fine_accuracy': overall_fine_acc,\n",
                "        'coarse_predictions': np.array(all_coarse_preds),\n",
                "        'coarse_labels': np.array(all_coarse_labels),\n",
                "        'fine_predictions': np.array(all_fine_preds),\n",
                "        'fine_labels': np.array(all_fine_labels),\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model for evaluation\n",
                "model.load_state_dict(torch.load(f\"{PATHS['models']}/hierarchical_model_{MODEL_CONFIG['architecture']}.pth\"))\n",
                "\n",
                "# Evaluate on test set\n",
                "results = evaluate_hierarchical_model(model, test_loader, DEVICE, region_idx_to_name)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"FULL HIERARCHICAL TEST RESULTS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nStage 1 (Coarse) Accuracy: {results['coarse_accuracy']:.4f}\")\n",
                "print(f\"\\nStage 2 (Fine) Accuracy per Region:\")\n",
                "for region, acc in results['fine_accuracy_per_region'].items():\n",
                "    print(f\"  {region}: {acc:.4f}\")\n",
                "print(f\"\\nOverall Fine Accuracy: {results['overall_fine_accuracy']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Final Model Information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model info\n",
                "final_info = {\n",
                "    'model_path': f\"{PATHS['models']}/hierarchical_model_{MODEL_CONFIG['architecture']}.pth\",\n",
                "    'architecture': MODEL_CONFIG['architecture'],\n",
                "    'coarse_architecture': MODEL_CONFIG['coarse_architecture'],\n",
                "    'fine_architecture': MODEL_CONFIG['fine_architecture'],\n",
                "    'training_mode': 'end-to-end (no freezing)',\n",
                "    'stage1_test_accuracy': stage1_info['test_accuracy'],\n",
                "    'stage2_best_val_accuracy': best_val_acc,\n",
                "    'coarse_test_accuracy': results['coarse_accuracy'],\n",
                "    'fine_test_accuracy_per_region': results['fine_accuracy_per_region'],\n",
                "    'overall_fine_test_accuracy': results['overall_fine_accuracy']\n",
                "}\n",
                "\n",
                "with open(f\"{PATHS['models']}/hierarchical_model_info_{MODEL_CONFIG['architecture']}.json\", 'w') as f:\n",
                "    json.dump(final_info, f, indent=2)\n",
                "\n",
                "print(f\"\\nFinal model info saved to: {PATHS['models']}/hierarchical_model_info_{MODEL_CONFIG['architecture']}.json\")\n",
                "print(\"\\nHierarchical end-to-end training complete! You can now use the model for inference.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
