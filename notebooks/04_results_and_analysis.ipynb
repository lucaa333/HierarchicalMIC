{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Results and Analysis\n",
                "\n",
                "## Hierarchical Classification: Architecture Comparison\n",
                "\n",
                "### Evaluation metrics: **Accuracy, Precision, Recall, F1-Score, AUC, ROC Curves**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import os\n",
                "import json\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import (\n",
                "    confusion_matrix, classification_report, accuracy_score,\n",
                "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
                ")\n",
                "from sklearn.preprocessing import label_binarize\n",
                "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
                "from tqdm import tqdm\n",
                "\n",
                "from config import (\n",
                "    DEVICE, DATA_CONFIG, MODEL_CONFIG, PATHS, set_seed, DEFAULT_MERGED_DATASETS\n",
                ")\n",
                "from utils.data_loader import create_hierarchical_dataset, REGION_FINE_CLASS_COUNTS\n",
                "from utils.hierarchical_model import HierarchicalClassificationModel\n",
                "\n",
                "# Set matplotlib style for PGF export\n",
                "matplotlib.rcParams.update({\n",
                "    \"axes.titlesize\": 14,\n",
                "    \"axes.labelsize\": 12,\n",
                "    \"xtick.labelsize\": 10,\n",
                "    \"ytick.labelsize\": 10,\n",
                "    \"legend.fontsize\": 10,\n",
                "    \"font.size\": 10,\n",
                "})\n",
                "\n",
                "set_seed(42)\n",
                "print(f\"Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Test Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test data\n",
                "train_loader, val_loader, test_loader, dataset_info = create_hierarchical_dataset(\n",
                "    datasets_to_include=DEFAULT_MERGED_DATASETS,\n",
                "    batch_size=DATA_CONFIG['batch_size'],\n",
                "    num_workers=DATA_CONFIG['num_workers']\n",
                ")\n",
                "\n",
                "print(f\"Test samples: {dataset_info['test_samples']}\")\n",
                "print(f\"Regions: {dataset_info['idx_to_region']}\")\n",
                "\n",
                "# Extract key info\n",
                "region_configs = dataset_info['region_num_classes']\n",
                "region_idx_to_name = dataset_info['idx_to_region']\n",
                "num_coarse_classes = len(region_idx_to_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Evaluate Stage 1 (Coarse) Models\n",
                "\n",
                "Load models from `stage1_coarse_*.pth` files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ARCHITECTURES_STAGE1 = ['efficientnet3d_b0', 'resnet18_3d', 'resnet34_3d', 'densenet121_3d', 'enhanced', 'base']\n",
                "\n",
                "stage1_results = {}\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"SCANNING FOR STAGE 1 (COARSE) MODELS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for arch in ARCHITECTURES_STAGE1:\n",
                "    model_path = f\"{PATHS['models']}/stage1_coarse_{arch}.pth\"\n",
                "    \n",
                "    if os.path.exists(model_path):\n",
                "        print(f\"\\nFound: {os.path.basename(model_path)}\")\n",
                "        \n",
                "        try:\n",
                "            # Create model\n",
                "            model = HierarchicalClassificationModel(\n",
                "                region_configs=region_configs,\n",
                "                architecture=arch,\n",
                "                coarse_model_type=arch,\n",
                "                fine_model_type=arch,\n",
                "                dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
                "                region_idx_to_name=region_idx_to_name,\n",
                "                num_total_organs=dataset_info['num_fine_classes'],\n",
                "                use_subtypes=False\n",
                "            ).to(DEVICE)\n",
                "            \n",
                "            # Load weights\n",
                "            checkpoint = torch.load(model_path, map_location=DEVICE)\n",
                "            model.load_state_dict(checkpoint, strict=False)\n",
                "            \n",
                "            print(f\"  -> Evaluating coarse classifier...\")\n",
                "            model.eval()\n",
                "            \n",
                "            all_preds, all_labels, all_probs = [], [], []\n",
                "            \n",
                "            with torch.no_grad():\n",
                "                for imgs, coarse_labels, _ in tqdm(test_loader, desc=f\"Stage1 {arch}\"):\n",
                "                    imgs = imgs.to(DEVICE, dtype=torch.float32)\n",
                "                    if imgs.max() > 1:\n",
                "                        imgs = imgs / 255.0\n",
                "                    coarse_labels = coarse_labels.long().to(DEVICE)\n",
                "                    \n",
                "                    logits = model.forward_coarse(imgs)\n",
                "                    probs = torch.softmax(logits, dim=1)\n",
                "                    preds = logits.argmax(1)\n",
                "                    \n",
                "                    all_preds.extend(preds.cpu().numpy())\n",
                "                    all_labels.extend(coarse_labels.cpu().numpy())\n",
                "                    all_probs.append(probs.cpu().numpy())\n",
                "            \n",
                "            y_true = np.array(all_labels)\n",
                "            y_pred = np.array(all_preds)\n",
                "            y_probs = np.concatenate(all_probs, axis=0)\n",
                "            \n",
                "            # Compute metrics\n",
                "            acc = accuracy_score(y_true, y_pred)\n",
                "            prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
                "            rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
                "            f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
                "            \n",
                "            # AUC\n",
                "            try:\n",
                "                y_true_bin = label_binarize(y_true, classes=list(range(num_coarse_classes)))\n",
                "                auc_val = roc_auc_score(y_true_bin, y_probs, average='weighted', multi_class='ovr')\n",
                "            except:\n",
                "                auc_val = None\n",
                "            \n",
                "            stage1_results[arch] = {\n",
                "                'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'auc': auc_val,\n",
                "                'predictions': y_pred, 'labels': y_true, 'probs': y_probs\n",
                "            }\n",
                "            print(f\"  -> Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"  -> Error: {e}\")\n",
                "\n",
                "print(f\"\\nStage 1 models evaluated: {list(stage1_results.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Evaluate Stage 2 (Fine) Models\n",
                "\n",
                "Load models from `hierarchical_model_*.pth` files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ARCHITECTURES_STAGE2 = ['efficientnet3d_b0', 'efficientnet3d_b0_bare_metal', 'resnet18_3d', 'resnet34_3d', 'densenet121_3d']\n",
                "\n",
                "stage2_results = {}\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"SCANNING FOR STAGE 2 (HIERARCHICAL) MODELS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for arch in ARCHITECTURES_STAGE2:\n",
                "    base_arch = arch.replace('_bare_metal', '')\n",
                "    \n",
                "    # Try new format first\n",
                "    model_path = f\"{PATHS['models']}/hierarchical_model_{arch}.pth\"\n",
                "    if not os.path.exists(model_path):\n",
                "        model_path = f\"{PATHS['models']}/hierarchical_{arch}.pth\"\n",
                "    \n",
                "    if os.path.exists(model_path):\n",
                "        print(f\"\\nFound: {os.path.basename(model_path)}\")\n",
                "        \n",
                "        try:\n",
                "            model = HierarchicalClassificationModel(\n",
                "                region_configs=region_configs,\n",
                "                architecture=base_arch,\n",
                "                coarse_model_type=base_arch,\n",
                "                fine_model_type=base_arch,\n",
                "                dropout_rate=MODEL_CONFIG['dropout_rate'],\n",
                "                region_idx_to_name=region_idx_to_name,\n",
                "                num_total_organs=dataset_info['num_fine_classes'],\n",
                "                use_subtypes=False\n",
                "            ).to(DEVICE)\n",
                "            \n",
                "            checkpoint = torch.load(model_path, map_location=DEVICE)\n",
                "            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
                "                model.load_state_dict(checkpoint['model_state_dict'])\n",
                "            else:\n",
                "                model.load_state_dict(checkpoint)\n",
                "            \n",
                "            print(f\"  -> Evaluating fine classifiers...\")\n",
                "            model.eval()\n",
                "            \n",
                "            all_fine_preds, all_fine_labels = [], []\n",
                "            \n",
                "            with torch.no_grad():\n",
                "                for imgs, coarse_labels, fine_labels in tqdm(test_loader, desc=f\"Stage2 {arch}\"):\n",
                "                    imgs = imgs.to(DEVICE, dtype=torch.float32)\n",
                "                    if imgs.max() > 1:\n",
                "                        imgs = imgs / 255.0\n",
                "                    coarse_labels = coarse_labels.long().to(DEVICE)\n",
                "                    fine_labels = fine_labels.long().to(DEVICE)\n",
                "                    \n",
                "                    # Use ground truth routing for fine evaluation\n",
                "                    for region_idx, region_name in region_idx_to_name.items():\n",
                "                        mask = (coarse_labels == region_idx)\n",
                "                        if not mask.any():\n",
                "                            continue\n",
                "                        \n",
                "                        region_imgs = imgs[mask]\n",
                "                        region_fine_labels = fine_labels[mask]\n",
                "                        \n",
                "                        fine_logits = model.forward_fine(region_imgs, region_name)\n",
                "                        fine_preds = fine_logits.argmax(1)\n",
                "                        \n",
                "                        all_fine_preds.extend(fine_preds.cpu().numpy())\n",
                "                        all_fine_labels.extend(region_fine_labels.cpu().numpy())\n",
                "            \n",
                "            y_true = np.array(all_fine_labels)\n",
                "            y_pred = np.array(all_fine_preds)\n",
                "            \n",
                "            acc = accuracy_score(y_true, y_pred)\n",
                "            prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
                "            rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
                "            f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
                "            \n",
                "            stage2_results[arch] = {\n",
                "                'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1,\n",
                "                'predictions': y_pred, 'labels': y_true\n",
                "            }\n",
                "            print(f\"  -> Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"  -> Error: {e}\")\n",
                "\n",
                "print(f\"\\nStage 2 models evaluated: {list(stage2_results.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Display Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# STAGE 1 RESULTS\n",
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"HIERARCHICAL MODEL COMPARISON - STAGE 1 (COARSE/REGION)\")\n",
                "print(\"=\"*100)\n",
                "print(f\"\\n{'Architecture':<28} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'AUC':<12}\")\n",
                "print(\"-\" * 100)\n",
                "\n",
                "for arch, m in stage1_results.items():\n",
                "    auc_str = f\"{m['auc']:.4f}\" if m['auc'] is not None else \"N/A\"\n",
                "    print(f\"{arch:<28} {m['accuracy']:<12.4f} {m['precision']:<12.4f} {m['recall']:<12.4f} {m['f1']:<12.4f} {auc_str:<12}\")\n",
                "\n",
                "# STAGE 2 RESULTS\n",
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"HIERARCHICAL MODEL COMPARISON - STAGE 2 (FINE/PATHOLOGY)\")\n",
                "print(\"=\"*100)\n",
                "print(f\"\\n{'Architecture':<28} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
                "print(\"-\" * 100)\n",
                "\n",
                "for arch, m in stage2_results.items():\n",
                "    print(f\"{arch:<28} {m['accuracy']:<12.4f} {m['precision']:<12.4f} {m['recall']:<12.4f} {m['f1']:<12.4f}\")\n",
                "\n",
                "print(\"-\" * 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Confusion Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(y_true, y_pred, title, labels=None, save_path=None):\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "    num_classes = len(cm)\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(12, 10))\n",
                "    \n",
                "    hm = sns.heatmap(\n",
                "        cm,\n",
                "        annot=True,\n",
                "        fmt='d',\n",
                "        cmap='viridis',\n",
                "        xticklabels=labels,\n",
                "        yticklabels=labels,\n",
                "        ax=ax,\n",
                "        square=True,\n",
                "        cbar=False,\n",
                "        linewidths=0,\n",
                "        annot_kws={\"size\": 10}\n",
                "    )\n",
                "    \n",
                "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=10)\n",
                "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=10)\n",
                "    \n",
                "    # Add custom colorbar\n",
                "    divider = make_axes_locatable(ax)\n",
                "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.15)\n",
                "    vmin = cm.min()\n",
                "    vmax = cm.max()\n",
                "    cbar = fig.colorbar(\n",
                "        hm.collections[0], \n",
                "        cax=cax,\n",
                "        drawedges=False,\n",
                "        ticks=np.linspace(vmin, vmax, 11)\n",
                "    )\n",
                "    cbar.solids.set_edgecolor(\"face\")\n",
                "    cbar.solids.set_rasterized(False)\n",
                "    cbar.set_label(\"Count\", fontsize=12)\n",
                "    cbar.outline.set_visible(False)\n",
                "    cbar.ax.tick_params(size=0, labelsize=10)\n",
                "    \n",
                "    ax.set_title(title, fontsize=14, fontweight='bold', pad=10)\n",
                "    ax.set_xlabel(\"Predicted Label\", fontsize=12, fontweight=\"bold\", labelpad=4)\n",
                "    ax.set_ylabel(\"True Label\", fontsize=12, fontweight=\"bold\", labelpad=4)\n",
                "    \n",
                "    # Disable rasterization for all artists\n",
                "    for artist in fig.findobj():\n",
                "        if hasattr(artist, \"set_rasterized\"):\n",
                "            artist.set_rasterized(False)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    \n",
                "    if save_path:\n",
                "        plt.savefig(save_path, bbox_inches=\"tight\", pad_inches=0.05, dpi=150)\n",
                "    \n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Stage 1 Confusion Matrices\n",
                "region_labels = [dataset_info['idx_to_region'][i] for i in range(len(dataset_info['idx_to_region']))]\n",
                "\n",
                "for arch, results in stage1_results.items():\n",
                "    plot_confusion_matrix(\n",
                "        results['labels'],\n",
                "        results['predictions'],\n",
                "        f'Confusion Matrix - Stage 1 ({arch})',\n",
                "        labels=region_labels,\n",
                "        save_path=f\"{PATHS['figures']}/confusion_coarse_{arch}.pgf\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Stage 2 Confusion Matrices\n",
                "for arch, results in stage2_results.items():\n",
                "    fine_unique = sorted(list(set(results['labels'])))\n",
                "    fine_labels_names = [str(i) for i in fine_unique]\n",
                "    \n",
                "    plot_confusion_matrix(\n",
                "        results['labels'],\n",
                "        results['predictions'],\n",
                "        f'Confusion Matrix - Stage 2 ({arch})',\n",
                "        labels=fine_labels_names,\n",
                "        save_path=f\"{PATHS['figures']}/confusion_fine_{arch}.pgf\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ROC Curves (Stage 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curves for Stage 1 (Coarse Classification)\n",
                "for arch, results in stage1_results.items():\n",
                "    if 'probs' not in results:\n",
                "        continue\n",
                "    \n",
                "    y_true = results['labels']\n",
                "    y_probs = results['probs']\n",
                "    \n",
                "    # Binarize labels\n",
                "    y_true_bin = label_binarize(y_true, classes=list(range(num_coarse_classes)))\n",
                "    \n",
                "    plt.figure(figsize=(10, 8))\n",
                "    \n",
                "    for i in range(num_coarse_classes):\n",
                "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
                "        roc_auc = auc(fpr, tpr)\n",
                "        region_name = region_idx_to_name[i]\n",
                "        plt.plot(fpr, tpr, label=f'{region_name} (AUC = {roc_auc:.3f})')\n",
                "    \n",
                "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
                "    plt.xlabel('False Positive Rate')\n",
                "    plt.ylabel('True Positive Rate')\n",
                "    plt.title(f'ROC Curves - Stage 1 (Coarse) - {arch}')\n",
                "    plt.legend(loc='lower right')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f\"{PATHS['figures']}/roc_stage1_{arch}.pgf\", bbox_inches=\"tight\", pad_inches=0.05, dpi=150)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ANALYSIS COMPLETE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nStage 1 (Coarse) models evaluated: {len(stage1_results)}\")\n",
                "print(f\"Stage 2 (Fine) models evaluated: {len(stage2_results)}\")\n",
                "\n",
                "if stage1_results:\n",
                "    best_stage1 = max(stage1_results.items(), key=lambda x: x[1]['accuracy'])\n",
                "    print(f\"\\nBest Stage 1 model: {best_stage1[0]} (Accuracy: {best_stage1[1]['accuracy']:.4f})\")\n",
                "\n",
                "if stage2_results:\n",
                "    best_stage2 = max(stage2_results.items(), key=lambda x: x[1]['accuracy'])\n",
                "    print(f\"Best Stage 2 model: {best_stage2[0]} (Accuracy: {best_stage2[1]['accuracy']:.4f})\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}