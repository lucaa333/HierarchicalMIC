{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Exploration: Merged 3D MedMNIST Datasets\n",
                "\n",
                "This notebook explores the **5 merged 3D MedMNIST datasets** used for hierarchical classification:\n",
                "- **OrganMNIST3D**: Multi-organ CT scans (11 classes)\n",
                "- **NoduleMNIST3D**: Lung nodules (2 classes: benign/malignant)\n",
                "- **AdrenalMNIST3D**: Adrenal gland CT scans (2 classes)\n",
                "- **FractureMNIST3D**: Rib fractures (3 classes)\n",
                "- **VesselMNIST3D**: Brain vessel MRA (2 classes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from collections import Counter\n",
                "\n",
                "from config import DEVICE, DATA_CONFIG, DEFAULT_MERGED_DATASETS, set_seed\n",
                "from utils.data_loader import create_hierarchical_dataset, REGION_DATASET_MAPPING\n",
                "\n",
                "set_seed(42)\n",
                "print(f\"Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Merged Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load all 5 merged datasets\n",
                "train_loader, val_loader, test_loader, dataset_info = create_hierarchical_dataset(\n",
                "    datasets_to_include=DEFAULT_MERGED_DATASETS,\n",
                "    batch_size=DATA_CONFIG['batch_size'],\n",
                "    num_workers=DATA_CONFIG['num_workers']\n",
                ")\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"MERGED DATASET INFO\")\n",
                "print(\"=\"*60)\n",
                "for key, value in dataset_info.items():\n",
                "    print(f\"{key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect all labels from training set\n",
                "all_coarse_labels = []\n",
                "all_fine_labels = []\n",
                "\n",
                "for imgs, coarse, fine in train_loader:\n",
                "    all_coarse_labels.extend(coarse.numpy().tolist())\n",
                "    all_fine_labels.extend(fine.numpy().tolist())\n",
                "\n",
                "coarse_counts = Counter(all_coarse_labels)\n",
                "fine_counts = Counter(all_fine_labels)\n",
                "\n",
                "print(\"\\nCoarse (Region) Distribution:\")\n",
                "for idx, count in sorted(coarse_counts.items()):\n",
                "    region = dataset_info['idx_to_region'][idx]\n",
                "    print(f\"  {region} ({idx}): {count} samples ({100*count/len(all_coarse_labels):.1f}%)\")\n",
                "\n",
                "print(f\"\\nFine Label Distribution (top 10):\")\n",
                "for label, count in sorted(fine_counts.items(), key=lambda x: -x[1])[:10]:\n",
                "    print(f\"  Class {label}: {count} samples ({100*count/len(all_fine_labels):.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot coarse distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Coarse distribution\n",
                "regions = [dataset_info['idx_to_region'][i] for i in sorted(coarse_counts.keys())]\n",
                "counts = [coarse_counts[i] for i in sorted(coarse_counts.keys())]\n",
                "colors = plt.cm.Set2(np.linspace(0, 1, len(regions)))\n",
                "\n",
                "axes[0].bar(regions, counts, color=colors)\n",
                "axes[0].set_xlabel('Region')\n",
                "axes[0].set_ylabel('Number of Samples')\n",
                "axes[0].set_title('Coarse (Region) Distribution')\n",
                "for i, (r, c) in enumerate(zip(regions, counts)):\n",
                "    axes[0].text(i, c + 50, str(c), ha='center', fontsize=10)\n",
                "\n",
                "# Fine distribution\n",
                "fine_labels_sorted = sorted(fine_counts.keys())\n",
                "fine_counts_sorted = [fine_counts[l] for l in fine_labels_sorted]\n",
                "\n",
                "axes[1].bar(range(len(fine_labels_sorted)), fine_counts_sorted, color='steelblue')\n",
                "axes[1].set_xlabel('Fine Class')\n",
                "axes[1].set_ylabel('Number of Samples')\n",
                "axes[1].set_title('Fine (Pathology) Distribution')\n",
                "axes[1].set_xticks(range(len(fine_labels_sorted)))\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../figures/data_distribution.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Sample Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_3d_sample(volume, title=\"3D Volume\", num_slices=6):\n",
                "    \"\"\"Visualize slices of a 3D volume.\"\"\"\n",
                "    if volume.ndim == 4:  # (C, D, H, W)\n",
                "        volume = volume[0]  # Take first channel\n",
                "    \n",
                "    depth = volume.shape[0]\n",
                "    slice_indices = np.linspace(0, depth-1, num_slices, dtype=int)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, num_slices, figsize=(15, 3))\n",
                "    for i, idx in enumerate(slice_indices):\n",
                "        axes[i].imshow(volume[idx], cmap='gray')\n",
                "        axes[i].set_title(f'Slice {idx}')\n",
                "        axes[i].axis('off')\n",
                "    \n",
                "    plt.suptitle(title)\n",
                "    plt.tight_layout()\n",
                "    return fig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize samples from each region\n",
                "print(\"Visualizing samples from each region...\\n\")\n",
                "\n",
                "region_samples = {region: None for region in dataset_info['idx_to_region'].values()}\n",
                "\n",
                "for imgs, coarse, fine in train_loader:\n",
                "    for i in range(len(imgs)):\n",
                "        region_idx = coarse[i].item()\n",
                "        region_name = dataset_info['idx_to_region'][region_idx]\n",
                "        if region_samples[region_name] is None:\n",
                "            region_samples[region_name] = (imgs[i].numpy(), fine[i].item())\n",
                "    \n",
                "    if all(v is not None for v in region_samples.values()):\n",
                "        break\n",
                "\n",
                "for region, (sample, fine_label) in region_samples.items():\n",
                "    fig = visualize_3d_sample(sample, title=f\"Region: {region}, Fine Label: {fine_label}\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Volume Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute volume statistics\n",
                "print(\"Computing volume statistics...\")\n",
                "\n",
                "all_means = []\n",
                "all_stds = []\n",
                "sample_count = 0\n",
                "max_samples = 500  # Limit for speed\n",
                "\n",
                "for imgs, _, _ in train_loader:\n",
                "    for img in imgs:\n",
                "        img_np = img.numpy()\n",
                "        if img_np.max() > 1:\n",
                "            img_np = img_np / 255.0\n",
                "        all_means.append(img_np.mean())\n",
                "        all_stds.append(img_np.std())\n",
                "        sample_count += 1\n",
                "    \n",
                "    if sample_count >= max_samples:\n",
                "        break\n",
                "\n",
                "print(f\"\\nVolume Statistics (from {sample_count} samples):\")\n",
                "print(f\"  Mean intensity: {np.mean(all_means):.4f} ± {np.std(all_means):.4f}\")\n",
                "print(f\"  Std intensity: {np.mean(all_stds):.4f} ± {np.std(all_stds):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"DATA EXPLORATION SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nDatasets included: {', '.join(dataset_info['datasets_included'])}\")\n",
                "print(f\"\\nSplit sizes:\")\n",
                "print(f\"  Train: {dataset_info['train_samples']:,}\")\n",
                "print(f\"  Val: {dataset_info['val_samples']:,}\")\n",
                "print(f\"  Test: {dataset_info['test_samples']:,}\")\n",
                "print(f\"\\nClasses:\")\n",
                "print(f\"  Coarse (regions): {dataset_info['num_coarse_classes']}\")\n",
                "print(f\"  Fine (pathologies): {dataset_info['num_fine_classes']}\")\n",
                "print(f\"\\nRegion mapping: {dataset_info['idx_to_region']}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
